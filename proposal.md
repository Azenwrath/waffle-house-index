# Capstone Proposal

### Name

#Waffle House Index v.2

### Product Overview

The Waffle House Index v.2 continues a proud tradition of FEMA-related statistics in tracking disasters in relation to show more information on the
link between Waffle House and national disasters. WHIV2 collects mentions of Waffle House on Twitter within the last seven days and performs sentiment
analysis on that data to determine how Twitter users feel about Waffle House.

### Specific Functionality
1. Django Admin Page: 
- pushes an API call to Twitter for all WH tweets in the last seven days on command(mvp) and then at a regular interval in accordance with API rate 
limits(Feature).
- Fetches weather data for each tweet if provided (Feature)
- Parse Twitter Data into format NLTK will accept
- Run NLTK sentiment analysis on Data
- Generate Graph? I'm unclear on whether this should be done server or client side.



2. Display Page:
-User facing page that shows a line chart of positive, negative, and neutral tweets across the last seven days (MVP)
-Show a random selection of tweets from the dataset (Feature)
-Show a plot correlating weather conditions to positive or negative sentiment (Feature)

User Interaction: 

Display Page:
1. User can click on a button underneath the displayed tweets in order to cause three new random tweets to appear. This will be an async call back to the database to provide
three new random tweets from the database.

Admin Page:
1. An Admin can force a call to the Twitter API for new tweets.
2. An Admin can view the current graph.
3. An Admin can browse tweets (feature)
 
### Data Model

-Tweet: Tweets are saved in the database in a manner consistent with the way the object is received from Twitter. The less I change the tweet, 
the more I can use other tools.

-Sentiment Model: NLTK will need a sentiment model saved somewhere.

-Graph/CSV: d3 seems pretty capable of creating the graph from CSV dynamically. I'll look in to how much precooking I can do, but my intention
is to store the CSV and let the front-end play with it. This also leaves me with more flexibility on the front-end at the cost of making the
browser do work.

-Tokenized Tweet Content: The meaty part of each tweet will need to be processed into tokenized versions for processing, but I do not intend to store that data.
Each tweet can have it's sentiment scores appended to it without needing to do any further evaluation of how the linguistic hotdog is made.

-Top Tweets: Superlative tweets should only be processed once per search and then stored in whatever manner allows the least resource intensive access.

### Technical Components

Django Site with:

1. PostgreSQL database of tweets to justify having already applied their sticker to my laptop or the future removal thereof.
2. Graph CSV in an AWS S3 bucket on my free year of AWS trial.
3. Hosting TBD. Data and processing needs should be minimal. PythonAnywhere or Heroku are the most likely candidates.
4. Graph generated by the d3 JavaScript library.
5. NLTK for sentiment analysis of tweets.
5. (feature) Move NLTK parsing to an AWS instance.


### Schedule

Write out the order in which you will tackle your technical components of your MVP.

1. Twitter API. Insuring that I can get good data from the Twitter API and parse it into the tweets I need is the crux of this project. I don't expect it to be very challenging, but the project hinges on there being a sufficient quantity of data regularly available. If I have to start storing historical tweets outside of the seven day free search window for historical tweets, then that needs to happen early.

2. Sentiment Analysis. I can make frequency graphs without appropriate sentiment anaylsis, but I consider this to be a core part of the project. I haven't done sentiment analysis with NLTK, but I know that it's a supported feature, and I'm a trained linguist. 

3. Graphing with d3. I suspect that creating simple graphs with d3 will be largely trivial to generate and time consuming to style. The main draw of the page is to have users view this piece. I expect that a sufficient graph will be simple, but the first sprint after MVP will be spent refining the look and feel of this graph.

4. Django. This project will eventually go online. The main templates will be relatively simple. Setting up the timed twitter scrapes and processing the data on the regular will be a larger challenge. I will setup Celery to handle task scheduling of Twitter scraping and tweet processing.

### Further Work

1. I'd like to push NLTK sentiment analysis from the free hosting I'll be using to AWS EC2 in order to get more practice with using the system.

2. I'd like to display and/or cluster geolocated tweets on an OpenLayers map. 

